{"cells":[{"cell_type":"code","execution_count":null,"id":"46300e53","metadata":{"id":"46300e53","outputId":"04c6548e-741d-4042-afd4-d2337ae56606"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cpu\n","Press 'q' to quit.\n"]}],"source":["import cv2\n","import torch\n","import numpy as np\n","from PIL import Image\n","from facenet_pytorch import MTCNN, InceptionResnetV1\n","import time\n","from concurrent.futures import ThreadPoolExecutor\n","from threading import Lock\n","import pyttsx3\n","\n","# Initialize text-to-speech engine\n","engine = pyttsx3.init()\n","\n","executor = ThreadPoolExecutor(max_workers=2)\n","task_lock = Lock()  # Lock to ensure thread-safe access to executor\n","\n","# Device setup\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","# Load models\n","mtcnn = MTCNN(keep_all=True, device=device, min_face_size=25)\n","resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n","\n","# Load embeddings and names from .npz\n","dataset_path = \"/Users/rajataggarwal/Desktop/dataset\"\n","data = np.load(f\"{dataset_path}/embeddings.npz\")\n","stored_embeddings = data['embeddings']\n","name_list = data['names']\n","\n","# Webcam setup\n","cap = cv2.VideoCapture(0) #cap = cv2.VideoCapture(0, cv2.CAP_FFMPEG)\n","#cap = cv2.VideoCapture(0, cv2.CAP_AVFOUNDATION)  # macOS\n","#cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n","cap.set(cv2.CAP_PROP_FRAME_WIDTH, 480)\n","cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 360)\n","\n","if not cap.isOpened():\n","    print(\"Error: Could not open camera.\")\n","    exit()\n","\n","DISTANCE_THRESHOLD = 0.75\n","frame_counter = 0\n","recognized_faces = []\n","processing = False\n","processing_time = 0.0\n","\n","def process_frame(input_frame, resized_frame):\n","    global recognized_faces, processing, processing_time\n","    start_time = time.time()\n","\n","    img_rgb = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)\n","    boxes, _ = mtcnn.detect(img_rgb)\n","    faces = mtcnn(Image.fromarray(img_rgb))\n","\n","    recognized = []\n","    if faces is not None and boxes is not None:\n","        try:\n","            faces = torch.stack([f for f in faces]).to(device)\n","        except:\n","            processing = False\n","            return\n","\n","        with torch.no_grad():\n","            embeddings = resnet(faces).cpu().numpy()\n","\n","        scale_x = input_frame.shape[1] / resized_frame.shape[1]\n","        scale_y = input_frame.shape[0] / resized_frame.shape[0]\n","\n","        for box, embedding in zip(boxes, embeddings):\n","           # distances = np.linalg.norm(stored_embeddings - embedding, axis=1) makes more comp intensive\n","            distances = np.sum((stored_embeddings - embedding) ** 2, axis=1)\n","            min_idx = np.argmin(distances)\n","            min_distance = distances[min_idx]\n","\n","            name = name_list[min_idx] if min_distance < DISTANCE_THRESHOLD else \"Unknown\"\n","\n","            x1, y1, x2, y2 = box\n","            x1 = int(x1 * scale_x)\n","            y1 = int(y1 * scale_y)\n","            x2 = int(x2 * scale_x)\n","            y2 = int(y2 * scale_y)\n","\n","            recognized.append(((x1, y1, x2, y2), name))\n","\n","    recognized_faces = recognized\n","    processing_time = time.time() - start_time\n","    processing = False\n","\n","print(\"Press 'q' to quit.\")\n","start_time = time.time()\n","\n","try:\n","    while time.time() - start_time < 10:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        frame_counter += 1\n","        display_frame = frame.copy()\n","\n","        if frame_counter % 3 == 0 and not processing:\n","            with task_lock:\n","                if executor._work_queue.qsize() < 2:\n","                    processing = True\n","                    resized_frame = cv2.resize(frame, (320, 240))  # Downsize for faster processing\n","                    #threading.Thread(target=process_frame, args=(frame.copy(), resized_frame)).start()\n","                    executor.submit(process_frame, frame.copy(), resized_frame)\n","\n","        # Draw recognized boxes\n","        for box, name in recognized_faces:\n","            x1, y1, x2, y2 = box\n","            cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n","            cv2.putText(display_frame, name, (x1, y1 - 10),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n","\n","        # Display FPS\n","        fps_text = f\"FPS: {1/processing_time:.2f}\" if processing_time > 0 else \"FPS: N/A\"\n","        cv2.putText(display_frame, fps_text, (10, 30),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n","\n","        # Show the frame\n","        cv2.imshow(\"Hybrid Real-Time Face Recognition\", display_frame)\n","\n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            break\n","\n","finally:\n","    cap.release()\n","    cv2.destroyAllWindows()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}